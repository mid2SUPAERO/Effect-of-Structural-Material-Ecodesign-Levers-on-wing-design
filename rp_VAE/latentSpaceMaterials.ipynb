{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37791139-97be-4ddb-8cbf-c7216db7ed0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T22:03:11.905393Z",
     "start_time": "2024-04-27T22:03:11.766932Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os, sys\n",
    "sys.path.append(os.path.realpath('./src/'))\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from scipy.spatial import ConvexHull\n",
    "from matplotlib.patches import Polygon, Ellipse\n",
    "from smallestEllipse import *\n",
    "\n",
    "from utilFuncs import to_np, to_torch\n",
    "from materialEncoder import MaterialEncoder\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "\n",
    "#matplotlib qt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ab3559-d61c-4b0f-ad1b-21b67199d2c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T22:03:14.768954Z",
     "start_time": "2024-04-27T22:03:14.759628Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessData():\n",
    "  df = pd.read_excel('./data/materials_2.xlsx')\n",
    "  dataIdentifier = {'name': df[df.columns[0]], 'className':df[df.columns[1]], 'classID':df[df.columns[2]]} # name of the material and type\n",
    "  trainInfo = np.log10(df[df.columns[3:]].to_numpy())\n",
    "  dataScaleMax = torch.tensor(np.max(trainInfo, axis = 0))\n",
    "  dataScaleMin = torch.tensor(np.min(trainInfo, axis = 0))\n",
    "  normalizedData = (torch.tensor(trainInfo) - dataScaleMin)/(dataScaleMax - dataScaleMin)\n",
    "  trainingData = normalizedData.clone().float()\n",
    "\n",
    "  dataInfo = {'UltimateStrength':{'idx':0,'scaleMin':dataScaleMin[0], 'scaleMax':dataScaleMax[0]},\\\n",
    "              'YieldStress':\t{'idx':1,'scaleMin':dataScaleMin[1], 'scaleMax':dataScaleMax[1]},\\\n",
    "              'MassDensity':\t{'idx':2,'scaleMin':dataScaleMin[2], 'scaleMax':dataScaleMax[2]},\\\n",
    "              'CostPerPound':{'idx':3,'scaleMin':dataScaleMin[3], 'scaleMax':dataScaleMax[3]},\\\n",
    "              'MeltingTempC':\t{'idx':4,'scaleMin':dataScaleMin[4], 'scaleMax':dataScaleMax[4]},\\\n",
    "              'MaxUseTempC':\t{'idx':5,'scaleMin':dataScaleMin[5], 'scaleMax':dataScaleMax[5]},\\\n",
    "              'Elong2Fail':{'idx':6,'scaleMin':dataScaleMin[6], 'scaleMax':dataScaleMax[6]},\\\n",
    "              'ElasticModulus':{'idx':7,'scaleMin':dataScaleMin[7], 'scaleMax':dataScaleMax[7]},\\\n",
    "              'CriticalityIdx':{'idx':8,'scaleMin':dataScaleMin[8], 'scaleMax':dataScaleMax[8]}}\n",
    "\n",
    "\n",
    "\n",
    "  return trainingData, dataInfo, dataIdentifier, trainInfo\n",
    "trainingData, dataInfo, dataIdentifier, trainInfo = preprocessData()\n",
    "numMaterialsInTrainingData, numFeatures = trainingData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89ee5a7c-ac8b-4c89-bfdd-d960468f1943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T22:03:24.447452Z",
     "start_time": "2024-04-27T22:03:15.352520Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Iter 0 reconLoss 2.36E+01 klLoss 7.12E-04 loss 2.36E+01\n",
      "Iter 500 reconLoss 3.20E-01 klLoss 2.22E-02 loss 3.42E-01\n",
      "Iter 1000 reconLoss 1.36E-01 klLoss 2.38E-02 loss 1.60E-01\n",
      "Iter 1500 reconLoss 8.94E-02 klLoss 2.32E-02 loss 1.13E-01\n",
      "Iter 2000 reconLoss 7.56E-02 klLoss 2.16E-02 loss 9.73E-02\n",
      "Iter 2500 reconLoss 8.01E-02 klLoss 2.03E-02 loss 1.00E-01\n",
      "Iter 3000 reconLoss 6.18E-02 klLoss 1.94E-02 loss 8.12E-02\n",
      "Iter 3500 reconLoss 5.22E-02 klLoss 1.90E-02 loss 7.12E-02\n",
      "Iter 4000 reconLoss 3.63E-02 klLoss 1.92E-02 loss 5.55E-02\n",
      "Iter 4500 reconLoss 2.33E-02 klLoss 1.88E-02 loss 4.21E-02\n",
      "Iter 5000 reconLoss 1.63E-02 klLoss 1.84E-02 loss 3.47E-02\n",
      "Iter 5500 reconLoss 1.88E-02 klLoss 1.83E-02 loss 3.71E-02\n",
      "Iter 6000 reconLoss 1.20E-02 klLoss 1.75E-02 loss 2.95E-02\n",
      "Iter 6500 reconLoss 1.97E-02 klLoss 1.72E-02 loss 3.69E-02\n",
      "Iter 7000 reconLoss 9.21E-03 klLoss 1.65E-02 loss 2.57E-02\n",
      "Iter 7500 reconLoss 7.34E-03 klLoss 1.61E-02 loss 2.34E-02\n",
      "Iter 8000 reconLoss 7.58E-03 klLoss 1.55E-02 loss 2.31E-02\n",
      "Iter 8500 reconLoss 6.70E-03 klLoss 1.53E-02 loss 2.20E-02\n",
      "Iter 9000 reconLoss 6.64E-03 klLoss 1.46E-02 loss 2.12E-02\n",
      "Iter 9500 reconLoss 7.37E-03 klLoss 1.45E-02 loss 2.18E-02\n",
      "Iter 10000 reconLoss 6.64E-03 klLoss 1.40E-02 loss 2.06E-02\n",
      "Iter 10500 reconLoss 7.02E-03 klLoss 1.38E-02 loss 2.09E-02\n",
      "Iter 11000 reconLoss 6.42E-03 klLoss 1.42E-02 loss 2.06E-02\n",
      "Iter 11500 reconLoss 5.32E-03 klLoss 1.33E-02 loss 1.86E-02\n",
      "Iter 12000 reconLoss 4.49E-03 klLoss 1.32E-02 loss 1.77E-02\n",
      "Iter 12500 reconLoss 6.30E-03 klLoss 1.30E-02 loss 1.93E-02\n",
      "Iter 13000 reconLoss 6.39E-03 klLoss 1.30E-02 loss 1.94E-02\n",
      "Iter 13500 reconLoss 4.83E-03 klLoss 1.26E-02 loss 1.74E-02\n",
      "Iter 14000 reconLoss 5.15E-03 klLoss 1.24E-02 loss 1.76E-02\n",
      "Iter 14500 reconLoss 5.69E-03 klLoss 1.24E-02 loss 1.81E-02\n",
      "Iter 15000 reconLoss 3.42E-03 klLoss 1.23E-02 loss 1.57E-02\n",
      "Iter 15500 reconLoss 3.84E-03 klLoss 1.18E-02 loss 1.56E-02\n",
      "Iter 16000 reconLoss 6.26E-03 klLoss 1.18E-02 loss 1.81E-02\n",
      "Iter 16500 reconLoss 5.17E-03 klLoss 1.20E-02 loss 1.72E-02\n",
      "Iter 17000 reconLoss 4.61E-03 klLoss 1.17E-02 loss 1.63E-02\n",
      "Iter 17500 reconLoss 4.60E-03 klLoss 1.16E-02 loss 1.62E-02\n",
      "Iter 18000 reconLoss 4.58E-03 klLoss 1.14E-02 loss 1.59E-02\n",
      "Iter 18500 reconLoss 7.30E-03 klLoss 1.16E-02 loss 1.89E-02\n",
      "Iter 19000 reconLoss 5.60E-03 klLoss 1.12E-02 loss 1.68E-02\n",
      "Iter 19500 reconLoss 3.52E-03 klLoss 1.13E-02 loss 1.48E-02\n",
      "Iter 20000 reconLoss 4.16E-03 klLoss 1.10E-02 loss 1.51E-02\n",
      "Iter 20500 reconLoss 3.04E-03 klLoss 1.09E-02 loss 1.39E-02\n",
      "Iter 21000 reconLoss 6.73E-03 klLoss 1.10E-02 loss 1.77E-02\n",
      "Iter 21500 reconLoss 3.25E-03 klLoss 1.08E-02 loss 1.40E-02\n",
      "Iter 22000 reconLoss 4.80E-03 klLoss 1.07E-02 loss 1.55E-02\n",
      "Iter 22500 reconLoss 3.17E-03 klLoss 1.07E-02 loss 1.39E-02\n",
      "Iter 23000 reconLoss 5.11E-03 klLoss 1.04E-02 loss 1.55E-02\n",
      "Iter 23500 reconLoss 5.70E-03 klLoss 1.07E-02 loss 1.64E-02\n",
      "Iter 24000 reconLoss 3.92E-03 klLoss 1.04E-02 loss 1.43E-02\n",
      "Iter 24500 reconLoss 2.85E-03 klLoss 1.05E-02 loss 1.34E-02\n",
      "Iter 25000 reconLoss 7.09E-03 klLoss 1.07E-02 loss 1.78E-02\n",
      "Iter 25500 reconLoss 3.93E-03 klLoss 1.04E-02 loss 1.43E-02\n",
      "Iter 26000 reconLoss 4.45E-03 klLoss 1.06E-02 loss 1.50E-02\n",
      "Iter 26500 reconLoss 3.40E-03 klLoss 1.01E-02 loss 1.35E-02\n",
      "Iter 27000 reconLoss 3.72E-03 klLoss 1.04E-02 loss 1.41E-02\n",
      "Iter 27500 reconLoss 4.12E-03 klLoss 1.04E-02 loss 1.45E-02\n",
      "Iter 28000 reconLoss 8.88E-03 klLoss 9.90E-03 loss 1.88E-02\n",
      "Iter 28500 reconLoss 3.01E-03 klLoss 1.00E-02 loss 1.30E-02\n",
      "Iter 29000 reconLoss 4.24E-03 klLoss 1.00E-02 loss 1.43E-02\n",
      "Iter 29500 reconLoss 2.99E-03 klLoss 9.88E-03 loss 1.29E-02\n",
      "Iter 30000 reconLoss 3.78E-03 klLoss 1.03E-02 loss 1.41E-02\n",
      "Iter 30500 reconLoss 3.57E-03 klLoss 1.01E-02 loss 1.36E-02\n",
      "Iter 31000 reconLoss 5.43E-03 klLoss 9.90E-03 loss 1.53E-02\n",
      "Iter 31500 reconLoss 3.43E-03 klLoss 9.99E-03 loss 1.34E-02\n",
      "Iter 32000 reconLoss 2.88E-03 klLoss 9.61E-03 loss 1.25E-02\n",
      "Iter 32500 reconLoss 2.17E-03 klLoss 9.81E-03 loss 1.20E-02\n",
      "Iter 33000 reconLoss 4.47E-03 klLoss 9.71E-03 loss 1.42E-02\n",
      "Iter 33500 reconLoss 3.22E-03 klLoss 9.87E-03 loss 1.31E-02\n",
      "Iter 34000 reconLoss 2.51E-03 klLoss 9.98E-03 loss 1.25E-02\n",
      "Iter 34500 reconLoss 3.18E-03 klLoss 9.61E-03 loss 1.28E-02\n",
      "Iter 35000 reconLoss 2.65E-03 klLoss 9.72E-03 loss 1.24E-02\n",
      "Iter 35500 reconLoss 3.37E-03 klLoss 9.50E-03 loss 1.29E-02\n",
      "Iter 36000 reconLoss 6.55E-03 klLoss 9.70E-03 loss 1.62E-02\n",
      "Iter 36500 reconLoss 4.35E-03 klLoss 9.61E-03 loss 1.40E-02\n",
      "Iter 37000 reconLoss 4.57E-03 klLoss 9.49E-03 loss 1.41E-02\n",
      "Iter 37500 reconLoss 2.87E-03 klLoss 9.39E-03 loss 1.23E-02\n",
      "Iter 38000 reconLoss 8.97E-03 klLoss 9.43E-03 loss 1.84E-02\n",
      "Iter 38500 reconLoss 3.72E-03 klLoss 9.58E-03 loss 1.33E-02\n",
      "Iter 39000 reconLoss 3.32E-03 klLoss 9.35E-03 loss 1.27E-02\n",
      "Iter 39500 reconLoss 4.20E-03 klLoss 9.45E-03 loss 1.37E-02\n",
      "training time : 58.39 \n"
     ]
    }
   ],
   "source": [
    "latentDim, hiddenDim = 2, 250\n",
    "numEpochs = 40000\n",
    "klFactor = 4.5e-5\n",
    "learningRate = 2e-3\n",
    "savedNet = './data/vaeNet.nt'\n",
    "vaeSettings = {'encoder':{'inputDim':numFeatures, 'hiddenDim':hiddenDim,\\\n",
    "                                          'latentDim':latentDim},\\\n",
    "               'decoder':{'latentDim':latentDim, 'hiddenDim':hiddenDim,\\\n",
    "                                          'outputDim':numFeatures}}\n",
    "materialEncoder = MaterialEncoder(trainingData, dataInfo, dataIdentifier, vaeSettings)\n",
    "start = time.perf_counter()\n",
    "convgHistory = materialEncoder.trainAutoencoder(numEpochs, klFactor, savedNet, learningRate)\n",
    "print('training time : {:.2F} '.format(time.perf_counter() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6d9bbc2-03a1-4184-a872-345bb731d94e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T22:03:25.805051Z",
     "start_time": "2024-04-27T22:03:25.803164Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b12594c0-a2f4-4f8e-a631-fd18c836f862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T22:03:27.163152Z",
     "start_time": "2024-04-27T22:03:26.697463Z"
    }
   },
   "outputs": [],
   "source": [
    "def plotConvergence(convg):\n",
    "  plt.figure();\n",
    "  strokes = ['--', '-.', '-', ':']\n",
    "  for ctr, key in enumerate(convg):\n",
    "    y = torch.as_tensor(convg[key]).detach().numpy()\n",
    "    y_mvavg = np.convolve(y, np.ones(20), 'valid') / 20.\n",
    "    plt.semilogy(y_mvavg, strokes[ctr], label = str(key))\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel(str(key))\n",
    "    plt.grid('True')\n",
    "    plt.legend(labels={'KL-Loss','Recon-Loss','Total Loss'})\n",
    "    # plt.legend('ReconLoss','KL-Loss','TotalLoss')\n",
    "    plt.savefig('./figures/convergence.pdf',bbox_inches='tight')\n",
    "\n",
    "plotConvergence(convgHistory)\n",
    "\n",
    "\n",
    "def plotLoss(convg):\n",
    "  plt.figure();\n",
    "  y = torch.as_tensor(convg['loss']).detach().numpy()\n",
    "  y_mvavg = np.convolve(y, np.ones(20), 'valid') / 20.\n",
    "  plt.semilogy(y_mvavg, '-', label = 'Total Loss')\n",
    "  plt.xlabel('Iterations')\n",
    "  plt.ylabel('Total Loss')\n",
    "  plt.grid('True')\n",
    "  # plt.legend(labels={'Total Loss'})\n",
    "\n",
    "plotLoss(convgHistory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e7694cd-ccd4-4d91-98a9-202373df3e11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T22:03:35.332428Z",
     "start_time": "2024-04-27T22:03:35.322630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MAR M247', 'IN 100', 'Inconel 718', 'Inconel 625', 'Ultimet (r)', 'Nickel Alloy 263', 'Hastelloy 276', 'Hastelloy C-4', 'Incoloy 27-7MO', 'Incoloy 825', 'Haynes 214', '17-4PH SS', 'Grade 304 SS', 'Nitronic 60', 'Ti-10%V-2%Fe-3%Al', 'Ti-6%Al-4%V', 'Ti Grade 4', '7068 Al', '7075 Al', '6061 Al']\n",
      "\t \t ------TRUE DATA----------\n",
      "material name\t\n",
      " \n",
      " \t \t ------RECON ERROR (%)----------\n",
      "material name\tUltimateStrength\tYieldStress\tMassDensity\tCostPerPound\tMeltingTempC\tMaxUseTempC\tElong2Fail\tElasticModulus\tCriticalityIdx\t\n",
      " \t -----MAX Error %----- \t \n",
      "UltimateStrength\t\t 1.3 \t\n",
      "YieldStress\t\t 1.2 \t\n",
      "MassDensity\t\t 0.6 \t\n",
      "CostPerPound\t\t 1.4 \t\n",
      "MeltingTempC\t\t 0.5 \t\n",
      "MaxUseTempC\t\t 2.5 \t\n",
      "Elong2Fail\t\t 2.8 \t\n",
      "ElasticModulus\t\t 1.5 \t\n",
      "CriticalityIdx\t\t 5.5 \t\n"
     ]
    }
   ],
   "source": [
    "matidxs = np.arange(trainInfo.shape[0]).astype(int)#0,11,20,46,54,69,91,5,92]\n",
    "props = ['UltimateStrength','YieldStress','MassDensity','CostPerPound','MeltingTempC','MaxUseTempC','Elong2Fail','ElasticModulus','CriticalityIdx']\n",
    "print([dataIdentifier['name'][i] for i in matidxs])\n",
    "print('\\t \\t ------TRUE DATA----------')\n",
    "print('material name', end = '\\t')\n",
    "\n",
    "\n",
    "def unnormalize(val, minval ,maxval):\n",
    "  return 10.**(minval + (maxval-minval)*val)\n",
    "def decodeAll():\n",
    "  vae = materialEncoder.vaeNet\n",
    "  decoded = vae.decoder(vae.encoder.z)\n",
    "  matProp = {'UltimateStrength':None,'YieldStress':None,\\\n",
    "             'MassDensity':None,'CostPerPound':None,'MeltingTempC':None,\\\n",
    "              'MaxUseTempC':None,'Elong2Fail':None,'ElasticModulus':None,'CriticalityIdx':None}\n",
    "  for k in props:\n",
    "    idx = materialEncoder.dataInfo[k]['idx']\n",
    "    scaleMax = materialEncoder.dataInfo[k]['scaleMax']\n",
    "    scaleMin = materialEncoder.dataInfo[k]['scaleMin']\n",
    "    matProp[k] = unnormalize(decoded[:,idx], scaleMin ,scaleMax)#scaleMin + decoded[:,idx]*(scaleMax - scaleMin)\n",
    "  return matProp\n",
    "\n",
    "matProp = decodeAll()\n",
    "\n",
    "\n",
    "merr = -1000000000.\n",
    "maxError = {'UltimateStrength':merr,'YieldStress':merr,\\\n",
    "             'MassDensity':merr,'CostPerPound':merr,'MeltingTempC':merr,\\\n",
    "              'MaxUseTempC':merr,'Elong2Fail':merr,'ElasticModulus':merr,'CriticalityIdx':merr}\n",
    "print('\\n \\n \\t \\t ------RECON ERROR (%)----------') \n",
    "print('material name', end = '\\t')\n",
    "for p in props:\n",
    "    print(p, end = '\\t')\n",
    "for i in range(trainInfo.shape[0]):\n",
    "\n",
    "  for p in props:\n",
    "    idx = materialEncoder.dataInfo[p]['idx']\n",
    "    trueData = 10**trainInfo[i,idx]\n",
    "    reconData = matProp[p][i]\n",
    "    err = torch.abs(100.*(trueData - reconData)/trueData)\n",
    "    if(err > maxError[p]):\n",
    "      maxError[p] = err\n",
    "\n",
    "\n",
    "\n",
    "print('\\n \\t -----MAX Error %----- \\t ', end = '\\n')\n",
    "for p in props:\n",
    "    print(p, end = '\\t')\n",
    "    print('\\t {:.1F} \\t'.format(maxError[p]), end='\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47268807",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T22:03:36.208122Z",
     "start_time": "2024-04-27T22:03:36.199629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \t -----Mean Error %----- \t \n",
      "UltimateStrength\t\t 0.3 \t\n",
      "YieldStress\t\t 0.5 \t\n",
      "MassDensity\t\t 0.2 \t\n",
      "CostPerPound\t\t 0.3 \t\n",
      "MeltingTempC\t\t 0.1 \t\n",
      "MaxUseTempC\t\t 0.5 \t\n",
      "Elong2Fail\t\t 0.7 \t\n",
      "ElasticModulus\t\t 0.2 \t\n",
      "CriticalityIdx\t\t 1.8 \t\n"
     ]
    }
   ],
   "source": [
    "merr = torch.tensor([0.])\n",
    "meanError = {'UltimateStrength':merr,'YieldStress':merr,\\\n",
    "             'MassDensity':merr,'CostPerPound':merr,'MeltingTempC':merr,\\\n",
    "              'MaxUseTempC':merr,'Elong2Fail':merr,'ElasticModulus':merr,'CriticalityIdx':merr}\n",
    "\n",
    "for i in range(trainInfo.shape[0]):\n",
    "  # if(i in matidxs): #\n",
    "  #   print(f\"\\n {dataIdentifier['name'][i]} \\t \", end = '')\n",
    "  for p in props:\n",
    "    idx = materialEncoder.dataInfo[p]['idx']\n",
    "    trueData = 10**trainInfo[i,idx]\n",
    "    reconData = matProp[p][i]\n",
    "    err = torch.abs(100.*(trueData - reconData)/trueData).cpu()\n",
    "    err = err.reshape((1,) + err.shape)\n",
    "    meanError[p] = torch.cat((meanError[p],err),0)\n",
    "    # meanError[p] = torch.cat([meanError[p],err],0)\n",
    "\n",
    "print('\\n \\t -----Mean Error %----- \\t ', end = '\\n')\n",
    "for p in props:\n",
    "    print(p, end = '\\t')\n",
    "    print('\\t {:.1F} \\t'.format(torch.mean(meanError[p])), end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb9b26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T22:03:36.834899Z",
     "start_time": "2024-04-27T22:03:36.826218Z"
    }
   },
   "outputs": [],
   "source": [
    "def plotLatent(ltnt1, ltnt2, plotHull, plotEllipse, annotateHead, saveFileName):\n",
    "    clrs = ['purple', 'blue', 'red', 'teal', 'black', 'magenta', 'olive']\n",
    "    mrkrSet = ['x','D','s','p','*','o','P']\n",
    "    colorcol = dataIdentifier['classID']\n",
    "    ptLabel = dataIdentifier['name']\n",
    "    autoencoder = materialEncoder.vaeNet\n",
    "    z = autoencoder.encoder.z.to('cpu').detach().numpy()\n",
    "    fig, ax = plt.subplots()\n",
    "    # matidxs = np.array([13,14,15,48,18,10,9,8,24,20,30,69,27,37,5,6,73,77,78,85,91,88,75,80,82]).astype(int)-2\n",
    "    matidxs = np.arange(trainInfo.shape[0]).astype(int)\n",
    "    for i in range(np.max(colorcol)+1): \n",
    "      zMat = np.vstack((z[colorcol == i,ltnt1], z[colorcol == i,ltnt2])).T\n",
    "      ax.scatter(zMat[:, 0], zMat[:, 1], marker=mrkrSet[i], c = clrs[i], s = 12)#clrs[i]\n",
    "\n",
    "      if(plotHull):\n",
    "        hull = ConvexHull(zMat)\n",
    "        cent = np.mean(zMat, 0)\n",
    "        pts = []\n",
    "        for pt in zMat[hull.simplices]:\n",
    "            pts.append(pt[0].tolist())\n",
    "            pts.append(pt[1].tolist())\n",
    "  \n",
    "        pts.sort(key=lambda p: np.arctan2(p[1] - cent[1],\n",
    "                                        p[0] - cent[0]))\n",
    "        pts = pts[0::2]  # Deleting duplicates\n",
    "        pts.insert(len(pts), pts[0])\n",
    "        # print(pts)\n",
    "        poly = Polygon(1.1*(np.array(pts)- cent) + cent,\n",
    "                       facecolor= clrs[i], alpha=0.2, edgecolor = 'black') #'black'\n",
    "        poly.set_capstyle('round')\n",
    "        plt.gca().add_patch(poly)\n",
    "        # ax.annotate(dataIdentifier['className'][i], (cent[0], cent[1]), size = 15, c = 'red')\n",
    "        # print(dataIdentifier['className'][i])\n",
    "\n",
    "      if(plotEllipse):\n",
    "        hull = ConvexHull(zMat)\n",
    "        cent = np.mean(zMat, 0) + np.array([0,-0.5])\n",
    "        pts = []\n",
    "        for pt in zMat[hull.simplices]:\n",
    "            pts.append(pt[0].tolist())\n",
    "            pts.append(pt[1].tolist())\n",
    "  \n",
    "        pts.sort(key=lambda p: np.arctan2(p[1] - cent[1],\n",
    "                                        p[0] - cent[0]))\n",
    "        pts = pts[0::2]  # Deleting duplicates\n",
    "        # pts.insert(len(pts), pts[0])\n",
    "        enclosing_ellipse = welzl(np.array(pts, dtype=float))\n",
    "        # plot resulting ellipse\n",
    "        center,a,b,t = enclosing_ellipse\n",
    "        elli = plot_ellipse(enclosing_ellipse, str='k')\n",
    "        ellipse = Ellipse(xy=center, width=2*a, height=2*b, angle=np.degrees(t), edgecolor='k', fc=clrs[i], alpha=0.3, lw=2)\n",
    "        ax.add_patch(ellipse)\n",
    "        # ax.annotate(dataIdentifier['className'][i], (cent[0], cent[1]), size = 15, c = 'black')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        # poly = Polygon(1.1*(np.array(pts)- cent) + cent,\n",
    "        #                facecolor= clrs[i], alpha=0.2, edgecolor = 'black') #'black'\n",
    "        # poly.set_capstyle('round')\n",
    "\n",
    "        # plt.gca().add_patch(poly)\n",
    "        # ax.annotate(dataIdentifier['className'][i], (cent[0], cent[1]), size = 15, c = 'red')\n",
    "        # print(dataIdentifier['className'][i])\n",
    "        # print(i)\n",
    "    \n",
    "    \n",
    "    ax.annotate('Ti Alloys', xy=(-2, 0.8), xytext=(-2,0.8), size = 20, c = 'black', xycoords='data',textcoords='data')\n",
    "    ax.annotate('Ni Alloys', xy=(-2, -2.7) ,xytext=(-2,-2.7), size = 20, c = 'black' ,xycoords='data',textcoords='data')\n",
    "    ax.annotate('Steels', xytext=(2.1,-0.8), xy=(1.5, -0.5),size = 20, c = 'black', xycoords='data',textcoords='data')\n",
    "    ax.annotate('Al Alloys', xytext=(2,0.8), xy=(1.5, 0.5),size = 20, c = 'black', xycoords='data',textcoords='data')\n",
    "\n",
    "    \n",
    "    # matidxs = [] \n",
    "    for i, txt in enumerate(ptLabel):\n",
    "      if(annotateHead == False or ( annotateHead == True and  i in matidxs)):\n",
    "        \n",
    "        ax.annotate(txt, (z[i,ltnt1], z[i,ltnt2]), size = 10, style='normal',c='green')\n",
    "        ax.scatter(z[i,ltnt1], z[i,ltnt2], marker='*', c = 'black', s = 56)\n",
    "\n",
    "  #   plt.axis('off')\n",
    "    ticks = [-3, -2,  -1., 0.,  1., 2, 3]\n",
    "    ticklabels = ['-3','-2', '-1', '0','1', '2','3']\n",
    "    plt.xticks(ticks, ticklabels, fontsize=18)\n",
    "    plt.yticks(ticks, ticklabels, fontsize=18)\n",
    "    plt.xlabel('$z_0$'.format(ltnt1), size = 18)\n",
    "    plt.ylabel('$z_1$'.format(ltnt2), size = 18)\n",
    "    # plt.title('Latent Space Representation')\n",
    "    minor_ticks = np.arange(-3, 3, 0.1)\n",
    "    ax.set_xticks(minor_ticks, minor=True)\n",
    "    ax.set_yticks(minor_ticks, minor=True)\n",
    "    # Hide the right and top spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    # ax.patch.set_edgecolor('black')  \n",
    "    # ax.patch.set_linewidth('1')  \n",
    "\n",
    "    # plt.grid(which='minor')\n",
    "    plt.grid(visible=None)\n",
    "    plt.savefig(saveFileName,bbox_inches='tight')\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "plotLatent(0, 1, plotHull = False, plotEllipse = True, annotateHead = True, saveFileName = './figures/latent.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0119b833",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T22:01:05.396706Z",
     "start_time": "2024-04-27T22:01:05.394321Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a358570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLatentWithPropertyNew(ltnt1 = 0, ltnt2 = 1):\n",
    "  n = 80\n",
    "  zmin, zmax = -3,3\n",
    "  X,Y = np.meshgrid(np.linspace(zmin, zmax, n), np.linspace(zmin, zmax, n))\n",
    "  Z = torch.zeros((n**2, vaeSettings['encoder']['latentDim'])).to('cpu')\n",
    "  Z[:,ltnt1], Z[:,ltnt2] = to_torch(X.reshape(-1)), to_torch(Y.reshape(-1))\n",
    "\n",
    "  vae = materialEncoder.vaeNet.to('cpu')\n",
    "  trainData_z_np = to_np(vae.encoder.z)\n",
    "  decoded = vae.decoder(Z)\n",
    "\n",
    "\n",
    "\n",
    "  #-------------------------------------------#\n",
    "  props = ['YieldStress']\n",
    "  cutOff = [2.5,5]; \n",
    "  for p in props:\n",
    "    idx = materialEncoder.dataInfo[p]['idx']\n",
    "    scaleMax = materialEncoder.dataInfo[p]['scaleMax']\n",
    "    scaleMin = materialEncoder.dataInfo[p]['scaleMin']\n",
    "\n",
    "    matPropVal = 10.**(scaleMin + decoded[:,idx]*(scaleMax - scaleMin))\n",
    "\n",
    "    fig, ax =plotLatent(0, 1, plotHull = False, plotEllipse = True, annotateHead = True, saveFileName = './figures/latent.pdf')\n",
    "    # surf = ax.contourf(X, Y, (to_np(matPropVal).reshape((n,n))), levels = 20, cmap='coolwarm', alpha = 0.0)\n",
    "    surf = ax.contour(X, Y, (to_np(matPropVal).reshape((n,n))), levels = 15, cmap='coolwarm', alpha = 0.8)\n",
    "    \n",
    "    # surf = ax.contourf(X, Y, (to_np(matPropVal).reshape((n,n))), levels = cutOff, alpha = 0.3,\\\n",
    "    # colors=['g', 'g'], extend='both')\n",
    "    # surf.cmap.set_over('white')\n",
    "    # surf.cmap.set_under('white')\n",
    "    # surf.changed()\n",
    "\n",
    "    \n",
    "\n",
    "    plt.clabel(surf, inline=False, fontsize=10, fmt ='%0.2f', colors = 'black')\n",
    "    ax.set_xlabel('$z_0$')\n",
    "    ax.set_ylabel('$z_1$')\n",
    "    ax.set_title(p+' Contour Plot')\n",
    "    cbar = plt.colorbar(surf)\n",
    "    cbar.set_label('({:s})'.format(str(p)+' in MPa'))\n",
    "    plt.savefig('./figures/{:s}_latentField.pdf'.format(p), dpi=200, bbox_inches='tight')\n",
    "\n",
    "  #-------------------------------------------#\n",
    "  \n",
    "\n",
    "plt.close('all')\n",
    "plt.figure()\n",
    "plotLatentWithPropertyNew()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mae-ac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
